{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1\n",
    "\n",
    "Run this to create the function that translate the MULTIPOLYGON string from geo-network to MultiPolygon array in GeoJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# original = \"MULTILINESTRING((-177.74411010742188 -13.038644790649414,-178.20994567871094 -13.532644271850586,-178.66815185546875 -14.000577926635742,-180 -14.845966826181044),(180 -14.845966826181044,179.51083374023438 -15.151217460632324,179.3552703857422 -15.259571075439453,179.10226440429688 -15.414399147033691,178.74452209472656 -15.648521423339844,177.78695678710938 -16.244556427001953))\"\n",
    "\n",
    "def get_elements(a_str: str) -> list:\n",
    "    if re.compile(r'\\)\\),\\s*\\(\\(').search(a_str):\n",
    "        a_str = re.sub(r'\\)\\),\\s*\\(\\(', ');;(', a_str)\n",
    "        elements = a_str.split(';;')\n",
    "    else:\n",
    "        elements = []\n",
    "        elements.append(a_str)\n",
    "    return elements\n",
    "\n",
    "def translate_coordinates(element: str) -> list:\n",
    "    mp = re.sub(r'^\\(', '', element)\n",
    "    mp = re.sub(r'\\)$', '', mp)\n",
    "    coors = mp.split(\",\")\n",
    "    ar = []\n",
    "    for coor in coors:\n",
    "        ar.append([float(i) for i in coor.strip().split(\" \")])\n",
    "    return ar\n",
    "\n",
    "def translate_trajectory_multipolygon(elements: list) -> list:\n",
    "    results = []\n",
    "    for i, element in enumerate(elements):\n",
    "        processed_ar = []\n",
    "        if re.compile(r'\\),\\s*\\(').search(element):\n",
    "            element = re.sub(r'\\),\\s*\\(', ');(', element)\n",
    "            sub_elements = element.split(');(')\n",
    "            for sub_element in sub_elements:\n",
    "                processed_ar.append(translate_coordinates(sub_element))\n",
    "        else:\n",
    "            processed_ar.append(translate_coordinates(element))\n",
    "        results.append(processed_ar)\n",
    "    return results\n",
    "\n",
    "def translate_multilinestring(elements: list) -> list:\n",
    "    results = []\n",
    "    if re.compile(r'\\),\\s*\\(').search(elements[0]):\n",
    "        element = re.sub(r'\\),\\s*\\(', ');(', elements[0])\n",
    "        sub_elements = element.split(');(')\n",
    "        for sub_element in sub_elements:\n",
    "            results.append(translate_coordinates(sub_element))\n",
    "    else:\n",
    "        results.append(translate_coordinates(element))\n",
    "    return results\n",
    "\n",
    "def translate_linestring(elements: list) -> list:\n",
    "    return translate_coordinates(elements[0])\n",
    "\n",
    "\n",
    "def translate_point(elements: list) -> list:\n",
    "    return translate_coordinates(elements[0])[0]\n",
    "\n",
    "\n",
    "def translate_geometry(original: str) -> list:\n",
    "    if re.compile(r'^LINESTRING\\s*\\(').search(original):\n",
    "        a_str = re.sub(r'\\)$', '', re.sub(r'LINESTRING\\s*\\(', '', original))\n",
    "        return 'LineString', translate_linestring(get_elements(a_str))\n",
    "\n",
    "    if re.compile(r'^MULTILINESTRING\\s*\\(').search(original):\n",
    "        a_str = re.sub(r'\\)$', '', re.sub(r'MULTILINESTRING\\s*\\(', '', original))\n",
    "        elements = get_elements(a_str)\n",
    "        return 'MultiLineString', translate_multilinestring(elements)\n",
    "    \n",
    "    if re.compile(r'^MULTIPOLYGON\\s*\\(').search(original):\n",
    "        a_str = re.sub(r'\\)\\)$', '', re.sub(r'MULTIPOLYGON\\s*\\(\\(', '', original))\n",
    "        return 'MultiPolygon', translate_trajectory_multipolygon(get_elements(a_str))\n",
    "\n",
    "    if re.compile(r'^POINT\\s*\\(').search(original):\n",
    "        a_str = re.sub(r'POINT\\s*', '', original)\n",
    "        return 'Point', translate_point(get_elements(a_str))\n",
    "\n",
    "\n",
    "# results = translate_geometry(original)\n",
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL server information\n",
      "{'user': 'postgres', 'dbname': 'soop_sst', 'host': '127.0.0.1', 'port': '5432', 'tty': '', 'options': '', 'sslmode': 'prefer', 'sslcompression': '0', 'gssencmode': 'prefer', 'krbsrvname': 'postgres', 'target_session_attrs': 'any'} \n",
      "\n",
      "You are connected to -  ('PostgreSQL 13.8 (Ubuntu 13.8-1.pgdg20.04+1) on x86_64-pc-linux-gnu, compiled by gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0, 64-bit',) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import Error\n",
    "\n",
    "try:\n",
    "    # Connect to an existing database\n",
    "    connection = psycopg2.connect(user=\"postgres\",\n",
    "                                  password=\"password123\",\n",
    "                                  host=\"127.0.0.1\",\n",
    "                                  port=\"5432\",\n",
    "                                  database=\"soop_sst\")\n",
    "    # Create a cursor to perform database operations\n",
    "    cursor = connection.cursor()\n",
    "    # Print PostgreSQL details\n",
    "    print(\"PostgreSQL server information\")\n",
    "    print(connection.get_dsn_parameters(), \"\\n\")\n",
    "    # Executing a SQL query\n",
    "    cursor.execute(\"SELECT version();\")\n",
    "    # Fetch result\n",
    "    record = cursor.fetchone()\n",
    "    print(\"You are connected to - \", record, \"\\n\")\n",
    "except (Exception, Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21620\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SELECT ST_AsText(geom) FROM soop_sst.soop_sst_nrt_trajectory_map WHERE ST_AsText(geom) IS NOT NULL;\")\n",
    "geom_astxt_records = [record[0] for record in cursor.fetchall()]\n",
    "print(len(geom_astxt_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Some init setting, replace the API key for your instance\n",
    "\n",
    "import urllib.request as request\n",
    "import requests as postApi\n",
    "import json\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"ApiKey WTlTdUNZVUJUWGtsWTg4N1Z2T1Q6cFFadkFicGdSbFNnbVdPRkNrcWVKdw==\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vhnguyen/anaconda3/envs/architecturereview/lib/python3.9/site-packages/urllib3/connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ec2-54-253-84-18.ap-southeast-2.compute.amazonaws.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"acknowledged\":true,\"shards_acknowledged\":true,\"index\":\"search-soop-sst-postgres\"}\n"
     ]
    }
   ],
   "source": [
    "# Create the correct Mapping, the key here is to map the geoPolygon to geo_shape, the elastic do not guess the type correct and\n",
    "# hence need to override it.\n",
    "x = postApi.put('https://ec2-54-253-84-18.ap-southeast-2.compute.amazonaws.com:9200/search-soop-sst-postgres', headers=headers, json={\n",
    "    \"settings\": {\n",
    "        \"index\": {\n",
    "            \"number_of_shards\": \"1\",\n",
    "            \"analysis\": {\n",
    "                \"filter\": {\n",
    "                    \"front_ngram\": {\n",
    "                        \"type\": \"edge_ngram\",\n",
    "                        \"min_gram\": \"1\",\n",
    "                        \"max_gram\": \"12\"\n",
    "                    },\n",
    "                    \"bigram_joiner\": {\n",
    "                        \"max_shingle_size\": \"2\",\n",
    "                        \"token_separator\": \"\",\n",
    "                        \"output_unigrams\": \"false\",\n",
    "                        \"type\": \"shingle\"\n",
    "                    },\n",
    "                    \"bigram_max_size\": {\n",
    "                        \"type\": \"length\",\n",
    "                        \"max\": \"16\",\n",
    "                        \"min\": \"0\"\n",
    "                    },\n",
    "                    \"en-stem-filter\": {\n",
    "                        \"name\": \"light_english\",\n",
    "                        \"type\": \"stemmer\",\n",
    "                        \"language\": \"light_english\"\n",
    "                    },\n",
    "                    \"bigram_joiner_unigrams\": {\n",
    "                        \"max_shingle_size\": \"2\",\n",
    "                        \"token_separator\": \"\",\n",
    "                        \"output_unigrams\": \"true\",\n",
    "                        \"type\": \"shingle\"\n",
    "                    },\n",
    "                    \"delimiter\": {\n",
    "                        \"split_on_numerics\": \"true\",\n",
    "                        \"generate_word_parts\": \"true\",\n",
    "                        \"preserve_original\": \"false\",\n",
    "                        \"catenate_words\": \"true\",\n",
    "                        \"generate_number_parts\": \"true\",\n",
    "                        \"catenate_all\": \"true\",\n",
    "                        \"split_on_case_change\": \"true\",\n",
    "                        \"type\": \"word_delimiter_graph\",\n",
    "                        \"catenate_numbers\": \"true\",\n",
    "                        \"stem_english_possessive\": \"true\"\n",
    "                    },\n",
    "                    \"en-stop-words-filter\": {\n",
    "                        \"type\": \"stop\",\n",
    "                        \"stopwords\": \"_english_\"\n",
    "                    }\n",
    "                },\n",
    "                \"analyzer\": {\n",
    "                    \"i_prefix\": {\n",
    "                        \"filter\": [\n",
    "                            \"cjk_width\",\n",
    "                            \"lowercase\",\n",
    "                            \"asciifolding\",\n",
    "                            \"front_ngram\"\n",
    "                        ],\n",
    "                        \"type\": \"custom\",\n",
    "                        \"tokenizer\": \"standard\"\n",
    "                    },\n",
    "                    \"iq_text_delimiter\": {\n",
    "                        \"filter\": [\n",
    "                            \"delimiter\",\n",
    "                            \"cjk_width\",\n",
    "                            \"lowercase\",\n",
    "                            \"asciifolding\",\n",
    "                            \"en-stop-words-filter\",\n",
    "                            \"en-stem-filter\"\n",
    "                        ],\n",
    "                        \"type\": \"custom\",\n",
    "                        \"tokenizer\": \"whitespace\"\n",
    "                    },\n",
    "                    \"q_prefix\": {\n",
    "                        \"filter\": [\n",
    "                            \"cjk_width\",\n",
    "                            \"lowercase\",\n",
    "                            \"asciifolding\"\n",
    "                        ],\n",
    "                        \"type\": \"custom\",\n",
    "                        \"tokenizer\": \"standard\"\n",
    "                    },\n",
    "                    \"iq_text_base\": {\n",
    "                        \"filter\": [\n",
    "                            \"cjk_width\",\n",
    "                            \"lowercase\",\n",
    "                            \"asciifolding\",\n",
    "                            \"en-stop-words-filter\"\n",
    "                        ],\n",
    "                        \"type\": \"custom\",\n",
    "                        \"tokenizer\": \"standard\"\n",
    "                    },\n",
    "                    \"iq_text_stem\": {\n",
    "                        \"filter\": [\n",
    "                            \"cjk_width\",\n",
    "                            \"lowercase\",\n",
    "                            \"asciifolding\",\n",
    "                            \"en-stop-words-filter\",\n",
    "                            \"en-stem-filter\"\n",
    "                        ],\n",
    "                        \"type\": \"custom\",\n",
    "                        \"tokenizer\": \"standard\"\n",
    "                    },\n",
    "                    \"i_text_bigram\": {\n",
    "                        \"filter\": [\n",
    "                            \"cjk_width\",\n",
    "                            \"lowercase\",\n",
    "                            \"asciifolding\",\n",
    "                            \"en-stem-filter\",\n",
    "                            \"bigram_joiner\",\n",
    "                            \"bigram_max_size\"\n",
    "                        ],\n",
    "                        \"type\": \"custom\",\n",
    "                        \"tokenizer\": \"standard\"\n",
    "                    },\n",
    "                    \"q_text_bigram\": {\n",
    "                        \"filter\": [\n",
    "                            \"cjk_width\",\n",
    "                            \"lowercase\",\n",
    "                            \"asciifolding\",\n",
    "                            \"en-stem-filter\",\n",
    "                            \"bigram_joiner_unigrams\",\n",
    "                            \"bigram_max_size\"\n",
    "                        ],\n",
    "                        \"type\": \"custom\",\n",
    "                        \"tokenizer\": \"standard\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"number_of_replicas\": \"1\"\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"dynamic\": \"true\",\n",
    "        \"dynamic_templates\": [\n",
    "            {\n",
    "                \"all_text_fields\": {\n",
    "                    \"match_mapping_type\": \"string\",\n",
    "                    \"mapping\": {\n",
    "                        \"analyzer\": \"iq_text_base\",\n",
    "                        \"fields\": {\n",
    "                            \"delimiter\": {\n",
    "                                \"analyzer\": \"iq_text_delimiter\",\n",
    "                                \"type\": \"text\",\n",
    "                                \"index_options\": \"freqs\"\n",
    "                            },\n",
    "                            \"joined\": {\n",
    "                                \"search_analyzer\": \"q_text_bigram\",\n",
    "                                \"analyzer\": \"i_text_bigram\",\n",
    "                                \"type\": \"text\",\n",
    "                                \"index_options\": \"freqs\"\n",
    "                            },\n",
    "                            \"prefix\": {\n",
    "                                \"search_analyzer\": \"q_prefix\",\n",
    "                                \"analyzer\": \"i_prefix\",\n",
    "                                \"type\": \"text\",\n",
    "                                \"index_options\": \"docs\"\n",
    "                            },\n",
    "                            \"enum\": {\n",
    "                                \"ignore_above\": 2048,\n",
    "                                \"type\": \"keyword\"\n",
    "                            },\n",
    "                            \"stem\": {\n",
    "                                \"analyzer\": \"iq_text_stem\",\n",
    "                                \"type\": \"text\"\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"geo_array_as_shape\": {\n",
    "                    \"match_mapping_type\": \"*\",\n",
    "                    \"match\": \"geoPolygon\",\n",
    "                    \"mapping\": { \"type\" : \"geo_shape\"}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}, verify=False);\n",
    "\n",
    "print(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21620/21620 [1:30:19<00:00,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL connection is closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# post document to elasticsearch indice\n",
    "for i in tqdm(range(len(geom_astxt_records))):\n",
    "    geojson_type, translated_geom = translate_geometry(geom_astxt_records[i])\n",
    "    data = {\n",
    "    \"geoPolygon\":\n",
    "        {\n",
    "            \"type\": geojson_type,\n",
    "            \"coordinates\": translated_geom\n",
    "        }\n",
    "    }\n",
    "    postApi.post(\n",
    "        \"https://ec2-54-253-84-18.ap-southeast-2.compute.amazonaws.com:9200/search-soop-sst-postgres/_doc\",\n",
    "        json = data,\n",
    "        verify=False,\n",
    "        headers=headers\n",
    "    )\n",
    "    \n",
    "# close database connection\n",
    "if (connection):\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    print(\"PostgreSQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a701007c31514b864d702fba59ad4cc8f823c5ee68f488fea6742cf9e3c7f8b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
